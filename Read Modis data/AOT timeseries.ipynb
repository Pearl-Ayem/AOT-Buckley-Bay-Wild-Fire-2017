{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from pyhdf.SD import SD, SDC\n",
    "import pprint\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy\n",
    "from mpl_toolkits.basemap import Basemap, cm\n",
    "import time\n",
    "import calendar\n",
    "import sys"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "home = Path.home()\n",
    "data_dir = home / Path(\"Desktop\\Edumacation\\GEOB 402\\FINAL PROJECT\\AOD Data\\MODIS files\")\n",
    "hdf_files=list(data_dir.glob(\"MOD04_L2*.hdf\"))\n",
    "\n",
    "#loops through all files listed in the text file\n",
    "for FILE_NAME in hdf_files:\n",
    "    FILE_NAME=str(data_dir / Path(FILE_NAME))\n",
    "    if '3K' in FILE_NAME: #then this is a 3km MODIS file\n",
    "        print('This is a 3km MODIS file. Saving... ')\n",
    "        dataFields=dict([(1,'Optical_Depth_Land_And_Ocean'),(2,'Image_Optical_Depth_Land_And_Ocean'),(3,'Land_sea_Flag'),(4,'Land_Ocean_Quality_Flag')])\n",
    "        # The name of the SDS to read\n",
    "    elif 'L2' in FILE_NAME: #Same as above but for 10km MODIS file\n",
    "        print('This is a 10km MODIS file. Saving... ')\n",
    "        dataFields=dict([(1,'Deep_Blue_Aerosol_Optical_Depth_550_Land'),(2,'AOD_550_Dark_Target_Deep_Blue_Combined'),(3,'AOD_550_Dark_Target_Deep_Blue_Combined_QA_Flag')])\n",
    "    else:\n",
    "        print('The file :',FILE_NAME, ' is not a valid MODIS file (or is named incorrectly). \\n')\n",
    "        continue\n",
    "    try:\n",
    "        # open the hdf file for reading\n",
    "        hdf=SD(FILE_NAME, SDC.READ)\n",
    "    except:\n",
    "        print('Unable to open file: \\n' + FILE_NAME + '\\n Skipping...')\n",
    "        continue\n",
    "\n",
    "    # Get lat and lon info\n",
    "    lat = hdf.select('Latitude')\n",
    "    lat=(lat.get()).ravel()\n",
    "    latitude = np.array(lat[:])\n",
    "    lon = hdf.select('Longitude')\n",
    "    lon=(lon.get()).ravel()\n",
    "    longitude = np.array(lon[:])\n",
    "    \n",
    "    #Get the scan start time from the hdf file. This is in number of seconds since Jan 1, 1993\n",
    "    scan_time=hdf.select('Scan_Start_Time')\n",
    "    scan_time=(scan_time.get()).ravel()\n",
    "    scan_time=scan_time[:]\n",
    "    #get the date info from scan_time\n",
    "    year=np.zeros(scan_time.shape[0])\n",
    "    month=np.zeros(scan_time.shape[0])\n",
    "    day=np.zeros(scan_time.shape[0])\n",
    "    hour=np.zeros(scan_time.shape[0])\n",
    "    min=np.zeros(scan_time.shape[0])\n",
    "    sec=np.zeros(scan_time.shape[0])\n",
    "    #Saves date info for each pixel to be saved later\n",
    "    for i in range(scan_time.shape[0]):\n",
    "        temp=time.gmtime(scan_time[i-1]+calendar.timegm(time.strptime('Dec 31, 1992 @ 23:59:59 UTC', '%b %d, %Y @ %H:%M:%S UTC')))\n",
    "        year[i-1]=temp[0]\n",
    "        month[i-1]=temp[1]\n",
    "        day[i-1]=temp[2]\n",
    "        hour[i-1]=temp[3]\n",
    "        min[i-1]=temp[4]\n",
    "        sec[i-1]=temp[5]\n",
    "\n",
    "\n",
    "#Begin saving to an output array\n",
    "    end=8+len(dataFields)#this is the number of columns needed (based on number of SDS read)\n",
    "    output=np.array(np.zeros((year.shape[0],end)))\n",
    "    output[0:,0]=year[:]\n",
    "    output[0:,1]=month[:]\n",
    "    output[0:,2]=day[:]\n",
    "    output[0:,3]=hour[:]\n",
    "    output[0:,4]=min[:]\n",
    "    output[0:,5]=sec[:]\n",
    "    output[0:,6]=latitude[:]\n",
    "    output[0:,7]=longitude[:]\n",
    "    #list for the column titles\n",
    "    tempOutput=[]\n",
    "    tempOutput.append('Year')\n",
    "    tempOutput.append('Month')\n",
    "    tempOutput.append('Day')\n",
    "    tempOutput.append('Hour')\n",
    "    tempOutput.append('Minute')\n",
    "    tempOutput.append('Second')\n",
    "    tempOutput.append('Latitude')\n",
    "    tempOutput.append('Longitude')\n",
    "    #This for loop saves all of the SDS in the dictionary at the top (dependent on file type) to the array (with titles)\n",
    "    for i in range(8,end):\n",
    "        SDS_NAME=dataFields[(i-7)] # The name of the sds to read\n",
    "        #get current SDS data, or exit program if the SDS is not found in the file\n",
    "        try:\n",
    "            sds=hdf.select(SDS_NAME)\n",
    "        except:\n",
    "            print('Sorry, your MODIS hdf file does not contain the SDS:',SDS_NAME,'. Please try again with the correct file type.')\n",
    "            continue\n",
    "        #get scale factor for current SDS\n",
    "        attributes=sds.attributes()\n",
    "        scale_factor=attributes['scale_factor']\n",
    "        fillvalue=attributes['_FillValue']\n",
    "        #get SDS data as a vector\n",
    "        data=(sds.get()).ravel()\n",
    "        data=np.array(data[:])\n",
    "        #The next few lines change fillvalue to NaN so that we can multiply valid values by the scale factor, then back to fill values\n",
    "        data=data.astype(float)\n",
    "        data[data==float(fillvalue)]=np.nan\n",
    "        data=data*scale_factor\n",
    "        data[np.isnan(data)]=fillvalue\n",
    "        #the SDS and SDS name are saved to arrays which will be written to the .txt file\n",
    "        output[0:,i]=data\n",
    "        tempOutput.append(SDS_NAME)\n",
    "    #changes list to an array so it can be stacked\n",
    "    tempOutput=np.asarray(tempOutput)\n",
    "    #This stacks the titles on top of the data\n",
    "    output=np.row_stack((tempOutput,output))\n",
    "    #save the new array to a text file, which is the name of the HDF4 file .txt instead of .hdf\n",
    "    np.savetxt('{0}.txt'.format(FILE_NAME[:-4]),output,fmt='%s',delimiter=',')\n",
    "print('\\nAll valid files have been saved successfully.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a 10km MODIS file. Saving... \n",
      "This is a 10km MODIS file. Saving... \n",
      "This is a 10km MODIS file. Saving... \n",
      "This is a 10km MODIS file. Saving... \n",
      "This is a 10km MODIS file. Saving... \n",
      "This is a 10km MODIS file. Saving... \n",
      "This is a 10km MODIS file. Saving... \n",
      "This is a 10km MODIS file. Saving... \n",
      "This is a 10km MODIS file. Saving... \n",
      "This is a 10km MODIS file. Saving... \n",
      "\n",
      "All valid files have been saved successfully.\n"
     ]
    }
   ],
   "source": [
    "home = Path.home()\n",
    "data_dir = home / Path(\"Desktop\\Edumacation\\GEOB 402\\FINAL PROJECT\\AOD Data\\MODIS files\")\n",
    "hdf_files=list(data_dir.glob(\"MOD04_L2*.hdf\"))\n",
    "\n",
    "row_count = 0\n",
    "#loops through all files listed in the text file\n",
    "for FILE_NAME in hdf_files:\n",
    "    FILE_NAME=str(data_dir / Path(FILE_NAME))\n",
    "    if '3K' in FILE_NAME: #then this is a 3km MODIS file\n",
    "        print('This is a 3km MODIS file. Saving... ')\n",
    "        dataFields=dict([(1,'Optical_Depth_Land_And_Ocean'),(2,'Image_Optical_Depth_Land_And_Ocean'),(3,'Land_sea_Flag'),(4,'Land_Ocean_Quality_Flag')])\n",
    "        # The name of the SDS to read\n",
    "    elif 'L2' in FILE_NAME: #Same as above but for 10km MODIS file\n",
    "        print('This is a 10km MODIS file. Saving... ')\n",
    "        dataFields=dict([(1,'Deep_Blue_Aerosol_Optical_Depth_550_Land'),(2,'AOD_550_Dark_Target_Deep_Blue_Combined'),(3,'AOD_550_Dark_Target_Deep_Blue_Combined_QA_Flag')])\n",
    "    else:\n",
    "        print('The file :',FILE_NAME, ' is not a valid MODIS file (or is named incorrectly). \\n')\n",
    "        continue\n",
    "    try:\n",
    "        # open the hdf file for reading\n",
    "        hdf=SD(FILE_NAME, SDC.READ)\n",
    "    except:\n",
    "        print('Unable to open file: \\n' + FILE_NAME + '\\n Skipping...')\n",
    "        continue\n",
    "\n",
    "    # Get lat and lon info\n",
    "    lat = hdf.select('Latitude')\n",
    "    lat=(lat.get()).ravel()\n",
    "    latitude = np.array(lat[:])\n",
    "    lon = hdf.select('Longitude')\n",
    "    lon=(lon.get()).ravel()\n",
    "    longitude = np.array(lon[:])\n",
    "    \n",
    "    #Get the scan start time from the hdf file. This is in number of seconds since Jan 1, 1993\n",
    "    scan_time=hdf.select('Scan_Start_Time')\n",
    "    scan_time=(scan_time.get()).ravel()\n",
    "    scan_time=scan_time[:]\n",
    "    #get the date info from scan_time\n",
    "    year=np.zeros(scan_time.shape[0])\n",
    "    month=np.zeros(scan_time.shape[0])\n",
    "    day=np.zeros(scan_time.shape[0])\n",
    "    hour=np.zeros(scan_time.shape[0])\n",
    "    min=np.zeros(scan_time.shape[0])\n",
    "    sec=np.zeros(scan_time.shape[0])\n",
    "    \n",
    "    #Saves date info for each pixel to be saved later\n",
    "    for i in range(scan_time.shape[0]):\n",
    "        temp=time.gmtime(scan_time[i-1]+calendar.timegm(time.strptime('Dec 31, 1992 @ 23:59:59 UTC', '%b %d, %Y @ %H:%M:%S UTC')))\n",
    "        year[i-1]=temp[0]\n",
    "        month[i-1]=temp[1]\n",
    "        day[i-1]=temp[2]\n",
    "        hour[i-1]=temp[3]\n",
    "        min[i-1]=temp[4]\n",
    "        sec[i-1]=temp[5]\n",
    "\n",
    "\n",
    "#Begin saving to an output array\n",
    "    end=8+len(dataFields)#this is the number of columns needed (based on number of SDS read)\n",
    "#     output=np.array(np.zeros((year.shape[0],end)))\n",
    "    output=np.array(np.zeros((274320,end)))\n",
    "    output[row_count:row_count+len(year),0]=year[:]\n",
    "    output[row_count:row_count+len(year),1]=month[:]\n",
    "    output[row_count:row_count+len(year),2]=day[:]\n",
    "    output[row_count:row_count+len(year),3]=hour[:]\n",
    "    output[row_count:row_count+len(year),4]=min[:]\n",
    "    output[row_count:row_count+len(year),5]=sec[:]\n",
    "    output[row_count:row_count+len(year),6]=latitude[:]\n",
    "    output[row_count:row_count+len(year),7]=longitude[:]\n",
    "    \n",
    "    #list for the column titles\n",
    "    tempOutput=[]\n",
    "    tempOutput.append('Year')\n",
    "    tempOutput.append('Month')\n",
    "    tempOutput.append('Day')\n",
    "    tempOutput.append('Hour')\n",
    "    tempOutput.append('Minute')\n",
    "    tempOutput.append('Second')\n",
    "    tempOutput.append('Latitude')\n",
    "    tempOutput.append('Longitude')\n",
    "    \n",
    "    row_count += len(year)\n",
    "    #This for loop saves all of the SDS in the dictionary at the top (dependent on file type) to the array (with titles)\n",
    "    for i in range(8,end):\n",
    "        SDS_NAME=dataFields[(i-7)] # The name of the sds to read\n",
    "        #get current SDS data, or exit program if the SDS is not found in the file\n",
    "        try:\n",
    "            sds=hdf.select(SDS_NAME)\n",
    "        except:\n",
    "            print('Sorry, your MODIS hdf file does not contain the SDS:',SDS_NAME,'. Please try again with the correct file type.')\n",
    "            continue\n",
    "        #get scale factor for current SDS\n",
    "        attributes=sds.attributes()\n",
    "        scale_factor=attributes['scale_factor']\n",
    "        fillvalue=attributes['_FillValue']\n",
    "        #get SDS data as a vector\n",
    "        data=(sds.get()).ravel()\n",
    "        data=np.array(data[:])\n",
    "        #The next few lines change fillvalue to NaN so that we can multiply valid values by the scale factor, then back to fill values\n",
    "        data=data.astype(float)\n",
    "        data[data==float(fillvalue)]=np.nan\n",
    "        data=data*scale_factor\n",
    "        data[np.isnan(data)]=fillvalue\n",
    "        #the SDS and SDS name are saved to arrays which will be written to the .txt file\n",
    "        output[0:,i]=data\n",
    "        tempOutput.append(SDS_NAME)\n",
    "#     #changes list to an array so it can be stacked\n",
    "#     tempOutput=np.asarray(tempOutput)\n",
    "#     #This stacks the titles on top of the data\n",
    "#     output=np.row_stack((tempOutput,output))\n",
    "#     #save the new array to a text file, which is the name of the HDF4 file .txt instead of .hdf\n",
    "#     np.savetxt('{0}.txt'.format(FILE_NAME[:-4]),output,fmt='%s',delimiter=',')\n",
    "print('\\nAll valid files have been saved successfully.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(274320, 11)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
